<!DOCTYPE html>
<html>
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-35E55J86ZR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-35E55J86ZR');
    </script>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="TIBET for Bias Evaluation">
    <meta property="og:title" content="TIBET for Bias Evaluation" />
    <meta property="og:description"
      content="Explore TIBET from ECCV 2024" />
    <meta property="og:url" content="tibet-ai.github.io" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/qualitative.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="TIBET for Bias Evaluation">
    <meta name="twitter:description"
      content="Explore TIBET from ECCV 2024">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image"
      content="static/images/qualitative.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="Bias, Evaluation, TIBET, tibet paper, eccv, eccv2024, explanability, dataset">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>TIBET: Identifying and Evaluating Biases in Text-to-Image Generative
      Models</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script
      src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
  </head>
  <body>

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">TIBET: Identifying and
                Evaluating Biases in Text-to-Image Generative Models</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://www.adityachinchure.com">Aditya
                    Chinchure</a><sup>*1</sup>,</span>
                <span class="author-block">
                  <a href="https://pushkershukla.github.io/shukla.github.io/">Pushkar
                    Shukla</a><sup>*2</sup>,</span>
                <span class="author-block">
                  <a href="https://gauravbh1010tt.github.io">Gaurav Bhatt</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="">Kiri Salij</a><sup>3</sup>,
                </span>
                <span class="author-block">
                  <a href="https://oid.wharton.upenn.edu/profile/kartikh/">Kartik
                    Hosanagar</a><sup>4</sup>,
                </span>
                <span class="author-block">
                  <a href="https://www.cs.ubc.ca/~lsigal/index.html">Leonid
                    Sigal</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://home.ttic.edu/~mturk/">Matthew
                    Turk</a><sup>2</sup>
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>University of British
                  Columbia & Vector Institute</span>
                <span class="author-block"><sup>2</sup>Toyota Technological
                  Institute at Chicago</span>
                <span class="author-block"><sup>3</sup>Carleton College</span>
                <span class="author-block"><sup>4</sup>The Wharton School, University of Pennsylvania</span>
                <br>
                <span class="author-block"><sup>*</sup>Equal contribution</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2312.01261"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- Supplementary PDF link -->
                  <!-- <span class="link-block">
                    <a href="static/pdfs/supplementary_material.pdf"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/TIBET-AI/TIBET" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2312.01261"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a class="external-link button is-normal is-rounded is-dark js-modal-trigger" data-target="modal-js-example" href="https://cfmodel.s3.us-west-2.amazonaws.com/TIBETdataset/TIBET-dataset.tar.gz">
                      <span class="icon">
                          <i class="far fa-images"></i>
                      </span>
                      <span>Data</span>
                    </a>
                  </span>
                </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <div id="modal-js-example" class="modal">
      <div class="modal-background"></div>
    
      <div class="modal-card">
        <header class="modal-card-head">
          <p class="modal-card-title">Thanks for downloading!</p>
          <button class="delete" aria-label="close"></button>
        </header>
        <section class="modal-card-body">
          The download should start automatically. If it doesn't, click <a href="https://cfmodel.s3.us-west-2.amazonaws.com/TIBETdataset/TIBET-dataset.tar.gz">here</a>.
        </section>
        <footer class="modal-card-foot">
          <button class="button is-success">Close</button>
        </footer>
      </div>
    
      <button class="modal-close is-large" aria-label="close"></button>
    </div>

    

    <!-- Teaser video-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <!-- <video poster id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/banner_video.mp4"
              type="video/mp4">
          </video> -->
          <img src="static/images/qualitative.png" alt="TIBET Example" />
          <h2 class="subtitle has-text-centered">
            <br>
            Analyse biases for any prompt, with any black-box T2I model, using TIBET!
          </h2>
          <h4 class="has-text-centered">
            Our approach calculates CAS and MAD scores to measure association with counterfactual prompts and 
                bias degree in generated images. Qualitative metrics like Top-K Concepts and Axis-Aligned Top-K Concepts offer post-hoc model explanations. 
                Additionally, our approach enables comparisons with counterfactual explanations.
          </h4>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Text-to-Image (TTI) generative models have shown great progress in the past few years in terms 
            of their ability to generate complex and high-quality imagery. At the same time, these models 
            have been shown to suffer from harmful biases, including exaggerated societal biases (e.g., gender, ethnicity), 
            as well as incidental correlations that limit such a model's ability to generate more diverse imagery. 
            In this paper, we propose a general approach to study and quantify a broad spectrum of biases, for any TTI model 
            and for any prompt, using counterfactual reasoning. Unlike other works that evaluate generated images on a predefined set 
            of bias axes, our approach automatically identifies potential biases that might be relevant to the given prompt, and
            measures those biases. In addition, we complement quantitative scores with post-hoc explanations in terms of 
            semantic concepts in the images generated. We show that our method is uniquely capable of explaining complex 
            multi-dimensional biases through semantic concepts, as well as the intersectionality between different biases 
            for any given prompt. We perform extensive user studies to illustrate that the results of our method and analysis 
            are consistent with human judgements.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Image carousel -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3">How it works</h2>
          <img src="static/images/mainfig.png" alt="TIBET" />
          <h4 class="has-text-centered">
            <br>
            Given an input prompt, we query an LLM (GPT-3) to identify axes of biases (Step 1), and generate counterfactual prompts 
            for each axis of bias (Step 2). Here, we show a sample of three counterfactual prompts for the physical appearance bias, 
            and two for the ableism bias. Next, we use a black-box TTI model (Stable Diffusion) to generate images for the initial 
            prompt as well as each counterfactual for all axes of bias (Step 3). In this example, we leverage VQA based concept 
            extraction to obtain a list of concepts and their frequencies for each set of images, and compare the concepts of the initial 
            set with concepts of each counterfactual to obtain CAS scores (Step 4). Finally, we compute MAD, a measure of how strong 
            the bias is in the images generated by the initial prompt (Step 5).
          </h4>
        </div>
      </div>
    </section>
    <!-- End image carousel -->

    <!-- Paper poster -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title">Poster</h2>

          <!-- <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe> -->
          Coming soon!

        </div>
      </div>
    </section>
    <!--End paper poster -->

    <!-- Example -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title">Example</h2>
          <img src="static/images/FullExampleUse.png" alt="TIBET Use" />
        </div>
      </div>
    </section>
    <!--End example -->

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@misc{chinchure2023tibet,
          title={TIBET: Identifying and Evaluating Biases in Text-to-Image Generative Models}, 
          author={Aditya Chinchure and Pushkar Shukla and Gaurav Bhatt and Kiri Salij and Kartik Hosanagar and Leonid Sigal and Matthew Turk},
          year={2023},
          eprint={2312.01261},
          archivePrefix={arXiv},
          primaryClass={cs.CV},
          url={https://arxiv.org/abs/2312.01261}, 
    }</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was
                adopted from the <a href="https://nerfies.github.io"
                  target="_blank">Nerfies</a> project page.
                You are free to borrow the of this website, we just ask that you
                link back to this page in the footer. <br> This website is
                licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

    <script>
      document.addEventListener('DOMContentLoaded', () => {
        // Functions to open and close a modal
        function openModal($el) {
          $el.classList.add('is-active');
        }

        function closeModal($el) {
          $el.classList.remove('is-active');
        }

        function closeAllModals() {
          (document.querySelectorAll('.modal') || []).forEach(($modal) => {
            closeModal($modal);
          });
        }

        // Add a click event on buttons to open a specific modal
        (document.querySelectorAll('.js-modal-trigger') || []).forEach(($trigger) => {
          const modal = $trigger.dataset.target;
          const $target = document.getElementById(modal);

          $trigger.addEventListener('click', () => {
            openModal($target);
          });
        });

        // Add a click event on various child elements to close the parent modal
        (document.querySelectorAll('.modal-background, .modal-close, .modal-card-head .delete, .modal-card-foot .button') || []).forEach(($close) => {
          const $target = $close.closest('.modal');

          $close.addEventListener('click', () => {
            closeModal($target);
          });
        });

        // Add a keyboard event to close all modals
        document.addEventListener('keydown', (event) => {
          if(event.key === "Escape") {
            closeAllModals();
          }
        });
      });
    </script>

  </body>
</html>
